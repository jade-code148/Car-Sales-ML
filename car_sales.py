# -*- coding: utf-8 -*-
"""Car Sales.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/126YWFuSXn5-j6DTjvbb_0DXRNkP--ELz

## Dataset Overview



This dataset includes various features related to car sales. It contains information such as customer names, gender, annual income, dealer details, car specifications, and more.</p>
</div>
"""

import numpy as np
import pandas as pd


df = pd.read_csv('/content/Car Sales.xlsx - car_data.csv')
df.sample(10).T

df.nunique()

df['Engine'].unique()

import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px


color_map = {'DoubleÂ\xa0Overhead Camshaft': 'blue', 'Overhead Camshaft': 'red'}
df['Color'] = df['Gender'].map(color_map)

# Create the 3D scatter plot with Plotly
fig = px.scatter_3d(df, x='Annual Income', y='Price ($)', z='Company', color='Engine', opacity=0.6,
                     color_discrete_map={'DoubleÂ\xa0Overhead Camshaft': 'blue', 'Overhead Camshaft': 'red'},
                     labels={'Annual Income': 'Ingreso Anual', 'Price ($)': 'Precio', 'Car_id': 'Car_id'},
                     title='Gráfico de Dispersión 3D con Engine como Color')

fig.show()

# 1. Price Distribution by Gender
plt.figure(figsize=(8, 6))
sns.boxplot(x='Gender', y='Price ($)', data=df)
plt.title('Price Distribution by Gender')
plt.xlabel('Gender')
plt.ylabel('Price ($)')
plt.show()

# 2. Annual Income Distribution
plt.figure(figsize=(8, 6))
sns.histplot(df['Annual Income'], kde=True)
plt.title('Distribution of Annual Income')
plt.xlabel('Annual Income')
plt.ylabel('Frequency')
plt.show()

# Grouping data by month and calculating the average price for each month
df['Date'] = pd.to_datetime(df['Date'])
df['Month'] = df['Date'].dt.to_period('M')
monthly_price = df.groupby('Month')['Price ($)'].mean().reset_index()
monthly_price['Month'] = monthly_price['Month'].dt.to_timestamp()

# Code for the modified line plot
plt.figure(figsize=(10, 6))
sns.lineplot(x='Month', y='Price ($)', data=monthly_price)
plt.title('Car Price Trend Over Time (Monthly Average)')
plt.xlabel('Month')
plt.ylabel('Average Price ($)')
plt.xticks(rotation=45)
plt.show()

# 4. Count of Cars by Body Style
plt.figure(figsize=(8, 6))
sns.countplot(y='Body Style', data=df)
plt.title('Count of Cars by Body Style')
plt.xlabel('Count')
plt.ylabel('Body Style')
plt.show()

# 5. Price Distribution by Car Company
plt.figure(figsize=(10, 6))
sns.boxplot(x='Price ($)', y='Company', data=df)
plt.title('Price Distribution by Car Company')
plt.xlabel('Price ($)')
plt.ylabel('Company')
plt.show()

# One-hot encoding for categorical columns
categorical_cols = ['Gender', 'Company', 'Model', 'Engine', 'Transmission', 'Color', 'Body Style', 'Dealer_Region']
df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

# Conversion of date and period to numerical features
df_encoded['Year'] = df['Date'].dt.year
df_encoded['Month'] = df['Month'].dt.month

# Retain the existing numerical columns
numerical_cols = ['Car_id', 'Annual Income', 'Price ($)', 'Phone']
df_encoded[numerical_cols] = df[numerical_cols]

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

df['Model'] = le.fit_transform(df['Model'])
df['Gender'] = le.fit_transform(df['Gender'])
df['Company'] = le.fit_transform(df['Company'])

df.dtypes

df_pca = df[['Annual Income', 'Price ($)', 'Company', 'Model', 'Gender']]
df_pca.dtypes

import plotly.express as px
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans

# Assuming df_pca is your original DataFrame prepared for PCA
# Apply PCA
pca = PCA(n_components=3)
reduced_data = pca.fit_transform(df_pca)

# Change the DataFrame to the new PCA dimensions
df_pca_reduced = pd.DataFrame(reduced_data, columns=['PC1', 'PC2', 'PC3'])

# Apply K-Means to create clusters
kmeans = KMeans(n_clusters=10, random_state=42)
clusters = kmeans.fit_predict(df_pca_reduced)

# Add the clusters column to the DataFrame
df_pca_reduced['Cluster'] = clusters

# Create the 3D clustering plot
fig = px.scatter_3d(df_pca_reduced, x='PC1', y='PC2', z='PC3', color='Cluster', opacity=0.7, size_max=5, title='3D Clustering')
fig.show()

!pip install catboost
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from xgboost import XGBRegressor 
from catboost import CatBoostRegressor  
from lightgbm import LGBMRegressor 
from sklearn.neural_network import MLPRegressor  
from sklearn.metrics import mean_absolute_error, r2_score

df = pd.read_csv('/content/Car Sales.xlsx - car_data.csv')

# Create a list of models
models = [
    ('Linear Regression', LinearRegression()),
    ('Ridge Regression', Ridge()),
    ('Lasso Regression', Lasso()),
    ('Decision Tree Regressor', DecisionTreeRegressor()),
    ('Random Forest Regressor', RandomForestRegressor()),
    ('Gradient Boosting Regressor', GradientBoostingRegressor()),
    ('SVR', SVR()),
    ('XGBoost Regressor', XGBRegressor()), 
    ('CatBoost Regressor', CatBoostRegressor(verbose=False)),  
    ('LightGBM Regressor', LGBMRegressor()), 
    ('MLP Regressor', MLPRegressor())  
]


# Encode the categorical columns with Label Encoding
label_encoder = LabelEncoder()
categorical_cols = ['Gender', 'Company', 'Model', 'Engine', 'Transmission', 'Color', 'Body Style', 'Dealer_Region']
for col in categorical_cols:
    df[col] = label_encoder.fit_transform(df[col])

# Extract relevant features and the target
X = df[['Gender', 'Model', 'Engine', 'Transmission', 'Company', 'Color', 'Body Style', 'Dealer_Region']]

# Apply PCA for dimensionality reduction
pca = PCA(n_components=3) 
X_pca = pca.fit_transform(X)

# Split the data into training and test sets

y = df['Price ($)']

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)



# Train and evaluate each model in the for loop
for model_name, model in models:
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    print(f'Model: {model_name}')
    print(f'Mean Absolute Error (MAE): {mae}')
    print(f'R-squared (R^2): {r2}')
    print('-' * 40)
